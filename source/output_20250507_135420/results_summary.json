{
    "timestamp": "2025-05-07 14:00:21",
    "dataset_info": {
        "size": 2593,
        "class_distribution": {
            "disgust": 801,
            "love": 798,
            "surprise": 504,
            "fear": 490
        }
    },
    "stacking_model": {
        "accuracy": 0.9653179190751445,
        "f1_score": 0.962247367395963,
        "classification_report": "              precision    recall  f1-score   support\n\n        fear       0.95      0.95      0.95        98\n        love       1.00      0.97      0.99       160\n     disgust       0.97      0.96      0.97       160\n    surprise       0.92      0.98      0.95       101\n\n    accuracy                           0.97       519\n   macro avg       0.96      0.97      0.96       519\nweighted avg       0.97      0.97      0.97       519\n"
    },
    "base_classifiers": {
        "MultinomialNB": {
            "accuracy": 0.882466281310212,
            "f1_score": 0.8651430227344926
        },
        "SVM": {
            "accuracy": 0.9633911368015414,
            "f1_score": 0.9599336665309686
        },
        "RandomForest": {
            "accuracy": 0.861271676300578,
            "f1_score": 0.8474774828122823
        }
    }
}